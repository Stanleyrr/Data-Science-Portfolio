from __future__ import division

import pandas as pd
import numpy as np
import sys
from datetime import datetime
now = datetime.now()
import math
import timeit
import datetime as dt
import time
import os
import glob

import urllib
import urllib.request
from urllib.request import urlopen
from zipfile import ZipFile
import json
import collections
from collections import Counter

pd.options.mode.chained_assignment = None
pd.set_option('max_rows', 400)

date = dt.datetime.today().strftime("%m_%d_%Y")

id_number = [119]

for x in id_number:    
    #'main_directory' is the directory path where you keep the files that relate to the id_number.
    main_directory = '/Users/stanleyruan/Downloads/' + str(x)    
    #Line 34-35 checks if the file path exists. If not, it will create one.
    if not os.path.exists(main_directory): 
        os.mkdir(main_directory)
    
    #Assuming that the actual ID file names start with a 'f', the 'list_of_full_ID_reports' variable stores the names of all files inside the main directory that are named 'f' followed by the id number, followed by any other character(s) and then '.csv'. 
    list_of_full_ID_reports = glob.glob(main_directory + '/f' + str(x) + '*.csv')
    #The 'full_report' variable in line 40 gets the path of the file from 'list_of_full_ID_reports' that has the latest modification time, meaning the newest file from that list. 
    full_report = max(list_of_full_ID_reports, key=os.path.getctime)
    #'whole_full' reads that 'full_report' into a Pandas dataframe for optimal data munging.
    whole_full=pd.read_csv(full_report, encoding='ISO-8859-1', index_col=None, low_memory=False).replace(np.nan, 'blank', regex=True)
    #Line 44 grabs all the files that contain the 'review_' + str(x) + '.csv' characters (these are basically files that contain the project IDs you are interested in).
    matching_list=glob.glob(main_directory + '/review_' + str(x) + '.csv')
    #Line 46 takes the latest file (based on modification time) from the 'matching_list' variable in line 44 and saves its path to 'matching_list' again.
    matching_list = max(matching_list, key = os.path.getctime)
    #Line 48 reads the file in path specified in line 46 into a Pandas dataframe. 
    matching_list=pd.read_csv(matching_list, encoding='ISO-8859-1', index_col=None, low_memory=False).replace(np.nan, 'blank', regex=True)    
    
    #Line 51 creates a dataframe subset called 'final_audit' that picks only the rows from 'whole_full' file where '_project_id' matches the '_project_id' from the 'matching_list' dataframe you created in line 48. 
    final_audit = whole_full[whole_full._project_id.isin(matching_list._project_id)].reset_index(drop=True)
    
    #'size' is the number of rows you want to draw randomly from each project_id in the final_audit file. You can set the size to any number you want.
    #'replace = False' means randomly picking the rows without replacement. If you are okay with replacement (which could create duplicate project IDs), you should set it to 'True'.
    size = 10
    replace = False
    Line 58-59 randomly draws the number of rows you specified in line 55, and assigns the complete output to a dataframe called 'final_audit2'.
    fn = lambda obj: obj.loc[np.random.choice(obj.index, size, replace),:]
    final_audit2=final_audit.groupby('project_id', as_index=False).apply(fn)    
    
    #Line 62-64 outputs the 'final_audit2' dataframe to an Excel workbook and puts it in a directory you specified.
    writer = pd.ExcelWriter(main_directory + '/full_report_audit' + date + '_' + str(now.hour) + '_' + str(now.minute) + '_' + str(x) + '.xlsx', engine='xlsxwriter', options={'strings_to_urls': False})
    final_audit2.to_excel(writer, sheet_name= "Sheet1")
    writer.save()
