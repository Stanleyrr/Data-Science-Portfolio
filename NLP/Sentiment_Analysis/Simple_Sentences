import nltk.classify.util
from nltk.classify import NaiveBayesClassifier
from nltk.corpus import names
from nltk.corpus import stopwords
import re

positive_vocab = [ 'awesome', 'outstanding', 'fantastic', 'terrific', 'good', 'nice', 'great', ':)' ]
negative_vocab = [ 'bad', 'terrible','useless', 'hate', ':(', 'it is horrible', 'horrible']
neutral_vocab = [ 'movie','the','sound','was','actors','did','know','words','not','so','really' ]

def word_feats(words):
    return dict([(word, True) for word in words])

positive_features_1 = [(word_feats(positive_vocab), 'pos')]
negative_features_1 = [(word_feats(negative_vocab), 'neg')]
neutral_features_1 = [(word_feats(neutral_vocab), 'neu')]

train_set = negative_features_1 + positive_features_1 + neutral_features_1

classifier = NaiveBayesClassifier.train(train_set) 

sentence = "Awesome movie. I like it. It is so bad."
sentences = sentence.lower().split('.')
for x in sentences:
    #The line below is a good way to handle empty words 
    if x != "":
        neg = 0
        pos = 0
        neu = 0
        #The line puts non-stop-words and non-empty-spaces into the variable 'words'.
        words = [word for word in x.split(" ") if word not in stopwords.words('english') if word != ""]
        classResult = classifier.classify(word_feats(words))
        if classResult == 'neg':
            neg = neg + 1
        if classResult == 'pos':
            pos = pos + 1
        print(str(x) + ' --> ' + str(classResult))
        #The following line returns, for each sentence, the number of positive words vs the number of negative words.
        print("\n%s: %d vs -%d\n"%(x,pos,neg))
            

